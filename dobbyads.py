# -*- coding: utf-8 -*-
"""DobbyAds.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/107uUvGIaMJRQUpWhNGHdCgK3gj7cF2O6
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

df = pd.read_csv("/content/drive/MyDrive/IMDB Dataset.csv")
df = df.iloc[1:]  # Remove the first row

df.columns

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords

# Preprocessing steps
stop_words = set(stopwords.words('english'))
def preprocess(text):
    text = text.lower()
    text = ''.join([c for c in text if c not in string.punctuation])
    text = ' '.join([word for word in text.split() if word not in stop_words])
    return text

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)

from sklearn.feature_extraction.text import CountVectorizer

vectorizer = CountVectorizer(stop_words='english')
X_train = vectorizer.fit_transform(X_train)
X_test = vectorizer.transform(X_test)

from sklearn.naive_bayes import MultinomialNB

clf = MultinomialNB()
clf.fit(X_train, y_train)

from sklearn.metrics import precision_score, recall_score, f1_score

# Make predictions on the test set
y_pred = clf.predict(X_test)

# Calculate precision, recall, and F1 score
precision = precision_score(y_test, y_pred, pos_label='positive')
recall = recall_score(y_test, y_pred, pos_label='positive')
f1 = f1_score(y_test, y_pred, pos_label='positive')

print(f"Precision: {precision:.3f}")
print(f"Recall: {recall:.3f}")
print(f"F1 score: {f1:.3f}")

from sklearn.metrics import accuracy_score

y_pred = clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")

import pickle

# Serialize the model and vectorizer using pickle and save them as .pkl files
with open('model.pkl', 'wb') as f:
    pickle.dump(clf, f)
with open('vectorizer.pkl', 'wb') as f:
    pickle.dump(vectorizer, f)

pip install transformers

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.svm import LinearSVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
from transformers import DistilBertTokenizerFast, TFDistilBertModel
import tensorflow as tf

# Load the dataset
df = pd.read_csv("/content/drive/MyDrive/IMDB Dataset.csv")
df = df.iloc[1:]  # Remove the first row

# Split the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords

# Preprocessing steps
stop_words = set(stopwords.words('english'))
def preprocess(text):
    text = text.lower()
    text = ''.join([c for c in text if c not in string.punctuation])
    text = ' '.join([word for word in text.split() if word not in stop_words])
    return text

# Define a pipeline for the linear SVM algorithm with CountVectorizer
svm_pipeline = Pipeline([
    ('vectorizer', CountVectorizer(stop_words='english')),
    ('clf', LinearSVC(max_iter=100)),
])

# Define a grid of hyperparameters to search over using GridSearchCV
svm_params = {
    'vectorizer__max_features': [1000, 5000, 10000],
    'clf__C': [0.1, 1, 10, 100],
}

# Perform a grid search over the hyperparameters
svm_gs = GridSearchCV(svm_pipeline, svm_params, cv=5)
svm_gs.fit(X_train, y_train)

# Evaluate the performance of the model on the test set
y_pred = svm_gs.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, pos_label='positive')
recall = recall_score(y_test, y_pred, pos_label='positive')
f1 = f1_score(y_test, y_pred, pos_label='positive')
print(f"Linear SVM with CountVectorizer: accuracy={accuracy:.3f}, precision={precision:.3f}, recall={recall:.3f}, F1 score={f1:.3f}")

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import pickle

# Load the data
df = pd.read_csv("/content/drive/MyDrive/IMDB Dataset.csv")
df = df.iloc[1:]  # Remove the first row

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)

# Create a vectorizer and transform the data
vectorizer = CountVectorizer(stop_words='english')
X_train = vectorizer.fit_transform(X_train)
X_test = vectorizer.transform(X_test)

# Create a Random Forest classifier and fit the data
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# Make predictions on the test set
y_pred = clf.predict(X_test)

# Calculate accuracy, precision, recall, and F1 score
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, pos_label='positive')
recall = recall_score(y_test, y_pred, pos_label='positive')
f1 = f1_score(y_test, y_pred, pos_label='positive')

# Print the evaluation metrics
print(f"Accuracy: {accuracy:.3f}")
print(f"Precision: {precision:.3f}")
print(f"Recall: {recall:.3f}")
print(f"F1 score: {f1:.3f}")

# Define a pipeline for the Naive Bayes algorithm with TF-IDF vectorizer
nb_pipeline = Pipeline([
    ('vectorizer', TfidfVectorizer(stop_words='english')),
    ('clf', MultinomialNB()),
])

#Define a grid of hyperparameters to search over using GridSearchCV
nb_params = {
'vectorizer__max_features': [1000, 5000, 10000],
'clf__alpha': [0.1, 1, 10],
}

#Perform a grid search over the hyperparameters
nb_gs = GridSearchCV(nb_pipeline, nb_params, cv=5)
nb_gs.fit(X_train, y_train)

#Evaluate the performance of the model on the test set
y_pred = nb_gs.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, pos_label='positive')
recall = recall_score(y_test, y_pred, pos_label='positive')
f1 = f1_score(y_test, y_pred, pos_label='positive')
print(f"Naive Bayes with TF-IDF vectorizer: accuracy={accuracy:.3f}, precision={precision:.3f}, recall={recall:.3f}, F1 score={f1:.3f}")

!pip install Django

!django-admin startproject movie_review_classification

# Commented out IPython magic to ensure Python compatibility.
# %cd movie_review_classification

!python manage.py startapp classifier

python manage.py migrate

!python manage.py runserver



